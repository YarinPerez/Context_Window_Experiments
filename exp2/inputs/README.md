# Experiment 2 Inputs

**Status**: ✅ Generated Successfully

This directory contains all input files for Experiment 2, including combined multi-document test files and metadata.

## Generation Results

✅ **5 combined document files created**
✅ **Total size**: ~4.3 MB (523K words)
✅ **Token count**: 15K → 390K tokens (across configurations)
✅ **Metadata**: Complete with document orders and statistics

## Directory Structure

```
inputs/
├── combined/                      # Generated multi-document test files
│   ├── test_02_docs.txt (101K)   # 2 documents, 12K words, ~16K tokens
│   ├── test_05_docs.txt (251K)   # 5 documents, 30K words, ~39K tokens
│   ├── test_10_docs.txt (501K)   # 10 documents, 60K words, ~78K tokens
│   ├── test_20_docs.txt (1.0M)   # 20 documents, 120K words, ~156K tokens
│   └── test_50_docs.txt (2.5M)   # 50 documents, 300K words, ~391K tokens
├── metadata.json (3.5K)          # Test configuration metadata
└── README.md                      # This file
```

## Actual Generated Files

| File | Size | Documents | Words | Est. Tokens | Status |
|------|------|-----------|-------|-------------|--------|
| test_02_docs.txt | 101 KB | 2 | 12,016 | 15,620 | ✅ |
| test_05_docs.txt | 251 KB | 5 | 30,040 | 39,052 | ✅ |
| test_10_docs.txt | 501 KB | 10 | 60,080 | 78,104 | ✅ |
| test_20_docs.txt | 1.0 MB | 20 | 120,160 | 156,208 | ✅ |
| test_50_docs.txt | 2.5 MB | 50 | 300,400 | 390,520 | ✅ |
| **Total** | **4.3 MB** | **87** | **522,696** | **679,504** | ✅ |

## Combined Document Format

Each combined document file contains multiple source documents concatenated with clear separators:

```
====================================
DOCUMENT 1 OF 5
FILE: file_01_end.txt
====================================

[Document content - approximately 6000 words]

====================================
DOCUMENT 2 OF 5
FILE: file_03_end.txt
====================================

[Document content - approximately 6000 words]

...
```

### Document Arrangement

**Key Principle**: The target document (`file_02_middle.txt` containing the answer "1995") is always placed at the **middle position** of each document set.

**Example for 5 documents:**
- Position 0: file_01_end.txt
- Position 1: file_03_end.txt
- Position 2: **file_02_middle.txt** ← TARGET (middle position)
- Position 3: file_04_middle.txt
- Position 4: file_06_middle.txt

## Metadata File

### Structure

The `metadata.json` file contains test configurations for all experiments:

```json
{
  "experiment_name": "Context Window Size Impact",
  "experiment_version": "2.0",
  "target_query": "What year was the organization founded?",
  "target_answer": "1995",
  "target_file": "file_02_middle.txt",
  "model": "claude-haiku-4.5",
  "test_configurations": [
    {
      "test_id": "test_02_docs",
      "num_documents": 2,
      "target_position": 1,
      "target_position_normalized": 0.5,
      "combined_file": "test_02_docs.txt",
      "document_order": ["file_01_end.txt", "file_02_middle.txt"],
      "total_word_count": 12000,
      "estimated_tokens": 16000
    }
    // ... additional configurations
  ]
}
```

### Field Descriptions

- **test_id**: Unique identifier for this test configuration
- **num_documents**: Total number of documents in this test
- **target_position**: Zero-indexed position of target document
- **target_position_normalized**: Position as fraction (0.0 to 1.0)
- **combined_file**: Filename of combined document
- **document_order**: Array of source filenames in order
- **total_word_count**: Approximate total words
- **estimated_tokens**: Estimated token count (word_count × 1.3)

## Source Documents

Source documents are loaded from `../exp1/inputs/`:
- file_01_end.txt through file_09_end.txt
- Each document: ~6000 words, ~35K characters, ~8K tokens
- Content: Business-themed text with embedded key data points

## Generation

Combined documents are generated by running:

```bash
cd ../scripts
python generate_combined_docs.py
```

This script:
1. Loads all 9 source documents
2. Applies document selection algorithm
3. Creates 5 combined document files
4. Generates metadata.json

## Document Selection Algorithm

The algorithm ensures target document is at the middle position:

1. Calculate middle position: `middle_pos = num_docs // 2`
2. Cycle through available files (excluding target)
3. Fill positions before middle
4. Insert target document at middle position
5. Fill remaining positions after middle
6. Allow duplicates when `num_docs > 9`

## Validation

After generation, verify:
- All 5 combined files exist in `combined/` directory
- metadata.json contains 5 test configurations
- Target document appears at middle position in each file
- Word counts match expectations (~6000 × num_docs)
